{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05426c32-44a1-4446-8c30-52d4656dca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",

    "DATASET_PATH = 'path_to_dataset'  # Update this with your dataset path\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n",
    "train_dataset = image_dataset_from_directory(DATASET_PATH, \n",
    "                                             validation_split=0.2, \n",
    "                                             subset=\"training\", \n",
    "                                             seed=123, \n",
    "                                             image_size=IMG_SIZE, \n",
    "                                             batch_size=BATCH_SIZE)\n",
    "\n",
    "test_dataset = image_dataset_from_directory(DATASET_PATH, \n",
    "                                           validation_split=0.2, \n",
    "                                           subset=\"validation\", \n",
    "                                           seed=123, \n",
    "                                           image_size=IMG_SIZE, \n",
    "                                           batch_size=BATCH_SIZE)\n",
    "\n",
    "NUM_CLASSES = 8  \n",
    "EPOCHS = 60  \n",
    "IMG_SIZE = 224\n",
    "PATCH_SIZE = 16\n",
    "D_MODEL = 768\n",
    "NUM_HEADS = 12\n",
    "NUM_LAYERS = 12\n",
    "MLP_DIM = 3072\n",
    "DROPOUT_RATE = 0.1\n",
    "LEARNING_RATE = 2e-5\n",
    "WEIGHT_DECAY = 1e-4\n",
    "class PatchEmbedding(layers.Layer):\n",
    "    def __init__(self, img_size=IMG_SIZE, patch_size=PATCH_SIZE, d_model=D_MODEL):\n",
    "        super().__init__()\n",
    "        self.num_patches = (img_size // patch_size) ** 2\n",
    "        self.projection = layers.Dense(d_model)\n",
    "        self.positional_encoding = self.add_weight(\"pos_enc\", shape=(1, self.num_patches, d_model))\n",
    "    def call(self, x):\n",
    "        patches = tf.image.extract_patches(x, [1, PATCH_SIZE, PATCH_SIZE, 1], [1, PATCH_SIZE, PATCH_SIZE, 1], [1, 1, 1, 1], 'VALID')\n",
    "        patches = tf.reshape(patches, [-1, self.num_patches, PATCH_SIZE * PATCH_SIZE * 3])\n",
    "        embedded_patches = self.projection(patches) + self.positional_encoding\n",
    "        return embedded_patches\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, mlp_dim, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.norm1 = layers.LayerNormalization()\n",
    "        self.attn = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model // num_heads)\n",
    "        self.cross_attn = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model // num_heads)\n",
    "        self.dropout1 = layers.Dropout(dropout_rate)\n",
    "        self.norm2 = layers.LayerNormalization()\n",
    "        self.mlp = keras.Sequential([\n",
    "            layers.Dense(mlp_dim, activation='gelu'),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Dense(d_model),\n",
    "        ])\n",
    "    def call(self, x):\n",
    "        attn_output = self.attn(x, x)\n",
    "        cross_attn_output = self.cross_attn(attn_output, attn_output)\n",
    "        x = self.norm1(x + self.dropout1(cross_attn_output))\n",
    "        mlp_output = self.mlp(x)\n",
    "        return self.norm2(x + mlp_output)\n",
    "class VisionTransformer(keras.Model):\n",
    "    def __init__(self, img_size=IMG_SIZE, patch_size=PATCH_SIZE, d_model=D_MODEL, num_layers=NUM_LAYERS, num_heads=NUM_HEADS, mlp_dim=MLP_DIM, num_classes=NUM_CLASSES, dropout_rate=DROPOUT_RATE):\n",
    "        super().__init__()\n",
    "        self.patch_embedding = PatchEmbedding(img_size, patch_size, d_model)\n",
    "        self.transformer_blocks = [TransformerBlock(d_model, num_heads, mlp_dim, dropout_rate) for _ in range(num_layers)]\n",
    "        self.class_token = self.add_weight(\"class_token\", shape=(1, 1, d_model))\n",
    "        self.norm = layers.LayerNormalization()\n",
    "        self.head = layers.Dense(num_classes, activation='softmax')\n",
    "    def call(self, x):\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        x = self.patch_embedding(x)\n",
    "        class_token = tf.tile(self.class_token, [batch_size, 1, 1])\n",
    "        x = tf.concat([class_token, x], axis=1)\n",
    "        for block in self.transformer_blocks:\n",
    "            x = block(x)\n",
    "        x = self.norm(x[:, 0])  # Use class token output\n",
    "        return self.head(x)\n",
    "vit_model = VisionTransformer()\n",
    "vit_model.compile(optimizer=tfa.optimizers.AdamW(learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY), \n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "vit_model.fit(train_dataset, epochs=EPOCHS)\n",
    "loss, accuracy = vit_model.evaluate(test_dataset)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for images, labels in test_dataset:\n",
    "    preds = vit_model.predict(images)\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=train_dataset.class_names))\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=train_dataset.class_names, yticklabels=train_dataset.class_names)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
